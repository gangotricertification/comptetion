{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36764bit88bf0dc1f5b5413fb6feaf512c2dfd80",
   "display_name": "Python 3.6.7 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import  stats\n",
    "from scipy.stats import binned_statistic\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "import warnings\n",
    "\n",
    "#methods\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb \n",
    "from sklearn import preprocessing,svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\ashum\\Desktop\\driven data  denguAI\\dengue_features_train.csv\")\n",
    "datay = pd.read_csv(r\"C:\\Users\\ashum\\Desktop\\driven data  denguAI\\dengue_labels_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = np.array(data[\"city\"])\n",
    "citty = [ 0 if i == \"sj\" else 1 for i in city]\n",
    "data = data.drop([\"city\",\"week_start_date\",\"year\"],axis=1)\n",
    "data['city'] = citty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_train = data.isnull().sum()\n",
    "null_train = null_train[null_train>0]\n",
    "null_train.sort_values(inplace = True)\n",
    "null_train.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproces(data):\n",
    "    #data.isnull().sum()    to check null value in dataframe\n",
    "    #normal_data.dropna(inplace=True)\n",
    "    normal_data = (data - data.mean())/data.std()\n",
    "    datax=normal_data.fillna(normal_data.mean())\n",
    "    return datax\n",
    "datay = datay[\"total_cases\"]\n",
    "#total_dat = datax\n",
    "#total_dat[\"total_cases\"] = datay\n",
    "datax = preproces(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dat = datax.copy()\n",
    "total_dat[\"total_cases\"] = datay\n",
    "print(total_dat.columns)\n",
    "print(datax.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "sns.heatmap(total_dat.corr(),vmax=0.7,square=True,linewidth=0.6,cmap=\"BuPu\")\n",
    "#sns.heatmap(datax.corr(),annot=True,fmt='d',cmap=\"BuPu\"(thischangescolor))  to get heat map with values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with output variable\n",
    "cor_target=abs(total_dat.corr()[\"total_cases\"])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.1]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_dat[[\"weekofyear\",\"city\",\"station_min_temp_c\"]].corr())\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_dat[[\"reanalysis_air_temp_k\",\"ndvi_sw\"]].corr())\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "c\n",
    "reanalysis_air_temp_k\n",
    "city\n",
    "weekofyear\n",
    "station_min_temp_c   #notclear\n",
    "ndvi_sw\n",
    "ndvi_se\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_heatmap = ['reanalysis_air_temp_k','city','weekofyear','station_min_temp_c','ndvi_sw','ndvi_se']\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Wrapper Method :A wrapper method needs one machine learning algorithm and uses its performance as evaluation criteria. This means, you feed the features to the selected Machine Learning algorithm and based on the model performance you add/remove the features. This is an iterative and computationally expensive process but it is more accurate than the filter method.\n",
    "\n",
    "There are different wrapper methods such as Backward Elimination, Forward Selection, Bidirectional Elimination and RFE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Backward Elimination\n",
    "\n",
    "The performance metric used here to evaluate feature performance is pvalue. If the pvalue is above 0.05 then we remove the feature, else we keep it.\n",
    "'''\n",
    "\n",
    "#Adding constant column of ones, mandatory for sm.OLS model\n",
    "x1 = sm.add_constant(datax)\n",
    "\n",
    "#Fitting sm.OLS model\n",
    "model_backward_elimination = sm.OLS(datay,x1).fit()\n",
    "model_backward_elimination.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward Elimination\n",
    "cols = list(datax.columns)\n",
    "pmax = 1\n",
    "while(len(cols)>0):\n",
    "    p=[]\n",
    "    x1 = datax[cols]\n",
    "    x1 = sm.add_constant(x1)\n",
    "    model_backward_elimination = sm.OLS(datay,x1).fit()\n",
    "    p = pd.Series(model_backward_elimination.pvalues.values[1:],index=cols)\n",
    "    pmax=max(p)\n",
    "    feature_pmax = p.idxmax()\n",
    "    if (pmax > 0.5):\n",
    "        cols.remove(feature_pmax)\n",
    "    else:\n",
    "        break\n",
    "col_backward_elimination = cols\n",
    "print(col_backward_elimination)\n",
    "print(len(col_backward_elimination))\n",
    "print(len(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "RFE (Recursive Feature Elimination)\n",
    "\n",
    "The Recursive Feature Elimination (RFE) method works by recursively removing attributes and building a model on those attributes that remain. It uses accuracy metric to rank the feature according to their importance. The RFE method takes the model to be used and the number of required features as input. It then gives the ranking of all the variables, 1 being most important. It also gives its support, True being relevant feature and False being irrelevant feature.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model,7)\n",
    "\n",
    "#Transforming data using RFE\n",
    "x_rfe = rfe.fit_transform(datax,datay)\n",
    "\n",
    "\n",
    "#Fitting the data to model\n",
    "model.fit(x_rfe,datay)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of features\n",
    "nof_list = np.arange(1,22)\n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof =0\n",
    "score_list=[]\n",
    "for n in range(len(nof_list)):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(datax,datay,test_size = 0.3,random_state = 1)\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model,nof_list[n])\n",
    "    x_train_rfe = rfe.fit_transform(x_train,y_train)\n",
    "    x_test_rfe = rfe.transform(x_test)\n",
    "    model.fit(x_train_rfe,y_train)\n",
    "    score = model.score(x_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if (score > high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "\n",
    "print(\"optimum no of features: %d\"%nof)\n",
    "print(\"score with %d features: %f\"%(nof,high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(datax.columns)\n",
    "model = LinearRegression()\n",
    "\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model,9)\n",
    "\n",
    "#Transforming data using RFE\n",
    "x_rfe = rfe.fit_transform(datax,datay)\n",
    "\n",
    "#Fitting the data to model\n",
    "model.fit(x_rfe,datay)\n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "col_rfe = temp[temp==True].index\n",
    "print(col_rfe)\n",
    "print(len(col_rfe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Embedded Method\n",
    "\n",
    "Embedded methods are iterative in a sense that takes care of each iteration of the model training process and carefully extract those features which contribute the most to the training for a particular iteration. Regularization methods are the most commonly used embedded methods which penalize a feature given a coefficient threshold.\n",
    "Here we will do feature selection using Lasso regularization. If the feature is irrelevant, lasso penalizes itâ€™s coefficient and make it 0. Hence the features with coefficient = 0 are removed and the rest are taken.\n",
    "'''\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LassoCV()\n",
    "reg.fit(datax,datay)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(datax,datay))\n",
    "coef = pd.Series(reg.coef_, index = datax.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "1. Filter method(like heatmap filteration) is less accurate. It is great while doing EDA, it can      also be used for checking multi co-linearity in data.\n",
    "2. Wrapper and Embedded methods give more accurate results but as they      are computationally expensive, these method are suited when you have      lesser features (~20).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_heatmap\n",
    "col_backward_elimination\n",
    "col_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = total_dat[col_heatmap].copy()\n",
    "train_meta.head(5)\n",
    "train_meta['total_cases'] = datay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "outlier removal\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(train_meta[(train_meta['reanalysis_air_temp_k'] > 0) & (train_meta['total_cases'] > 300)].index.tolist())\n",
    "b = set(train_meta[(train_meta['weekofyear'] > 0.5) & (train_meta['total_cases'] > 300)].index.tolist())\n",
    "c = set(train_meta[(train_meta['station_min_temp_c'] > 0) & (train_meta['total_cases'] > 300)].index.tolist())\n",
    "d = set(train_meta[(train_meta['ndvi_sw'] > -1 ) & (train_meta['ndvi_sw'] < 1 ) & (train_meta['total_cases'] > 300)].index.tolist())\n",
    "e = set(train_meta[(train_meta['ndvi_se'] > -1 ) & (train_meta['ndvi_se'] < 1 ) & (train_meta['total_cases'] > 300)].index.tolist())\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary = a.union(b).union(c).union(d).union(e)\n",
    "unnecessary = list(unnecessary)\n",
    "train_clean = train_meta.drop(unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_clean['total_cases']\n",
    "x = train_clean.drop(['total_cases'],axis=1)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=1)\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train,y_train)\n",
    "print(reg.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rfe = total_dat[col_rfe]\n",
    "train_rfe['total_cases'] = datay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rfe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(train_rfe[(train_rfe['reanalysis_air_temp_k'] > 0) & (train_rfe['total_cases'] > 200)].index.tolist())\n",
    "b = set(train_rfe[(train_rfe['weekofyear'] > 0.5) & (train_rfe['total_cases'] > 200)].index.tolist())\n",
    "c = set(train_rfe[(train_rfe['station_max_temp_c'] > 0) & (train_rfe['total_cases'] > 200)].index.tolist())\n",
    "d = set(train_rfe[(train_rfe['reanalysis_avg_temp_k'] > -1 ) & (train_rfe['reanalysis_avg_temp_k'] < 1 ) & (train_rfe['total_cases'] > 200)].index.tolist())\n",
    "e = set(train_rfe[(train_rfe['reanalysis_dew_point_temp_k'] > 0 ) & (train_rfe['total_cases'] > 200)].index.tolist())\n",
    "f = set(train_rfe[(train_rfe['reanalysis_relative_humidity_percent'] > -1 ) & (train_rfe['reanalysis_relative_humidity_percent'] < 1 ) & (train_rfe['total_cases'] > 200)].index.tolist())\n",
    "g = set(train_rfe[(train_rfe['reanalysis_specific_humidity_g_per_kg'] > -1 ) & (train_rfe['reanalysis_specific_humidity_g_per_kg'] < 1 ) & (train_rfe['total_cases'] > 200)].index.tolist())\n",
    "h = set(train_rfe[(train_rfe['reanalysis_tdtr_k'] < 0 ) & (train_rfe['total_cases'] > 200)].index.tolist())\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_rfe = a.union(b).union(c).union(d).union(e).union(f).union(g).union(h)\n",
    "unnecessary_rfe = list(unnecessary_rfe)\n",
    "train_clean_rfe = train_meta.drop(unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_clean_rfe['total_cases']\n",
    "x = train_clean_rfe.drop(['total_cases'],axis=1)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=123)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_train=y\n",
    "xx_train=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective='reg:linear',colsample_bytree=0.3,learning_rate = 0.1,max_depth=5, alpha=10, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(x_train,y_train)\n",
    "preds = xg_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "print(\"RMSE: %f\"%(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(xx_train,yy_train)\n",
    "preds = xg_reg.predict(xx_train)\n",
    "rmse = np.sqrt(mean_squared_error(yy_train,preds))\n",
    "print(\"RMSE: %f\"%(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(r\"C:\\Users\\ashum\\Desktop\\driven data  denguAI\\dengue_features_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}